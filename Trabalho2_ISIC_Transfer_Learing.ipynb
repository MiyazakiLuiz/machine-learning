{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nhShPYviZBl"
      },
      "source": [
        "# Trabalho 2: Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U_aGX_G7Hka"
      },
      "source": [
        "# **Alunos**\n",
        "\n",
        "*   André Dorte dos Santos\n",
        "*   Luiz Massao Miyazaki\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY17j0sUicN-"
      },
      "source": [
        "## Carregamento dos dados\n",
        "\n",
        "Os .zips contendo o dataset está no google drive. O código abaixo faz o download, e extrai o zip. Note que você precisará logar no Google para que esse processo seja possível. Caso haja alguma falha ou erro no processo, reinicie o notebook, e tente novamente.\n",
        "\n",
        "Depois desse processo, teremos no diretório:\n",
        "\n",
        "*   isic2017-train: 2000 imagens.\n",
        "*   isic2017-val: 150 imagens.\n",
        "*   isic2017-test: 650 imagens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWLEGyXxBxv4"
      },
      "source": [
        "!pip install PyDrive &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqt0wIlCOQM"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1EH2tlRi4Iqq8WfLOXl6hMc5jTeiIRzaW\"})\n",
        "downloaded.GetContentFile('isic2017-trainval.zip')\n",
        "!unzip -q isic2017-trainval.zip\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1uP1tCj6-T2FXxk7g7gqoC_SGOhqIQyrM\"})\n",
        "downloaded.GetContentFile('isic2017-test.zip')\n",
        "!unzip -q isic2017-test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOR7s4hjYxU"
      },
      "source": [
        "Em cada diretório, temos uma pasta contendo as lesões benignas ('/benign') e outra contendo as lesões malignas ('/malignant'). A separação dessa forma facilita a importação dos dados utilizando o keras.\n",
        "Estude o uso da ImageDataGenerator do Keras, pois ela facilita o uso de aumentação e pré-processamento dos dados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOpoVXbZcRy"
      },
      "source": [
        "# Aumentação de Dados\n",
        "\n",
        "1. Aplique aumentação de dados nas imagens, escolhendo três transformações. Mostre exemplos das\n",
        "transformações escolhidas e justifique por que elas são válidas neste dataset (1,0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frcOKiwUKN_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "998c9512-12c5-4b08-c058-688dc20fe156"
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from random import sample, seed\n",
        "seed(42)\n",
        "\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range= 20,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'isic2017-train/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'isic2017-val/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'isic2017-test/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3kdrnwq3yhB"
      },
      "source": [
        "Obtendo tamanhos dos batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_uVy6m865g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "150d16b9-64b1-483b-c19c-33a2e28514d0"
      },
      "source": [
        "print(len(train_generator))\n",
        "print(len(validation_generator))\n",
        "print(len(test_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63\n",
            "5\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Qrq_aXjve6"
      },
      "source": [
        "## Treinamento dos Modelos\n",
        "\n",
        "Com os dados carregados corretamente, basta treinar e avaliar o modelo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aROxmjnooXYg"
      },
      "source": [
        "# A métrica oficial da base de dados é a AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# função para avaliar modelos com base na métrica AUC\n",
        "def evaluation_model(eva_model, eva_data):\n",
        "  preds = eva_model.predict(eva_data)\n",
        "\n",
        "  batch_index = 0\n",
        "  data_list = []\n",
        "  while batch_index <= eva_data.batch_index:\n",
        "      _, label = eva_data.next()\n",
        "      data_list.extend(label)\n",
        "      batch_index = batch_index + 1\n",
        "\n",
        "  gt = np.argmax(data_list, axis=1)\n",
        "  auc = roc_auc_score(gt, preds[:,1])\n",
        "  print(\"auc :\", auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu0QxlJbwAlJ"
      },
      "source": [
        "# Modelo Baseline\n",
        "\n",
        "2. Como baseline, construa e treine um modelo convolucional simples (1,0).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgofyLp5R3MO"
      },
      "source": [
        "# Modelo Baseline\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "baseline_model = tf.keras.Sequential([\n",
        "  layers.Conv2D(\n",
        "    filters=10,\n",
        "    kernel_size=3\n",
        "  ),\n",
        "  layers.GlobalAveragePooling2D(),\n",
        "  layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7600t571OJig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "b8d5fe13-7dcc-46df-ba70-21cb21a735cb"
      },
      "source": [
        "# Treinamento Modelo Baseline\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001)\n",
        "baseline_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "baseline_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=63,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 28s 444ms/step - loss: 9.0537 - accuracy: 0.7200 - val_loss: 7.2930 - val_accuracy: 0.8133\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 28s 445ms/step - loss: 4.0320 - accuracy: 0.6935 - val_loss: 2.7611 - val_accuracy: 0.8067\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 28s 440ms/step - loss: 1.6311 - accuracy: 0.7090 - val_loss: 0.8216 - val_accuracy: 0.8133\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 29s 454ms/step - loss: 1.0844 - accuracy: 0.7145 - val_loss: 0.5691 - val_accuracy: 0.8133\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 28s 447ms/step - loss: 0.6853 - accuracy: 0.7615 - val_loss: 0.5148 - val_accuracy: 0.8200\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 28s 445ms/step - loss: 0.5817 - accuracy: 0.7815 - val_loss: 0.6567 - val_accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 28s 447ms/step - loss: 0.5816 - accuracy: 0.7870 - val_loss: 0.5775 - val_accuracy: 0.7933\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 28s 448ms/step - loss: 0.5249 - accuracy: 0.8025 - val_loss: 0.7373 - val_accuracy: 0.3867\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 28s 441ms/step - loss: 0.5486 - accuracy: 0.7815 - val_loss: 0.6202 - val_accuracy: 0.7733\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 28s 442ms/step - loss: 0.5212 - accuracy: 0.8005 - val_loss: 0.4765 - val_accuracy: 0.8067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55e48dd160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U35cX6SToVOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e943c499-3acd-4512-e9ce-8f60583e90d8"
      },
      "source": [
        "evaluation_model(baseline_model, validation_generator)\n",
        "score = baseline_model.evaluate(validation_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc : 0.6483333333333332\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.4765 - accuracy: 0.8067\n",
            "Valid loss: 0.47648289799690247\n",
            "Valid acc: 0.8066666722297668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8tzXN68vC15"
      },
      "source": [
        "3. Escolha uma arquitetura cuja implementação e pesos pré-treinados na ImageNet estejam disponíveis\n",
        "como extratora de features (1,0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFExowmswNkI"
      },
      "source": [
        "# Carregamento do modelo pré-treinado SEM as camadas densas (include_top = False)\n",
        "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyL6e_2IvCSg"
      },
      "source": [
        "4. Inicialmente, descarte a saída original e congele suas as camadas. Adicione uma nova camada de\n",
        "saída com o número de classes adequadas para este problema (1,0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWSQQiKsehDX"
      },
      "source": [
        "# Congela camadas pré-treinadas\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Insere novas camadas no fim da rede para classificação\n",
        "full_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# full_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN1eSMfzwqow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "95fe5502-972b-4fe1-a0b2-5d6e823e0b45"
      },
      "source": [
        "# Treinamento da última camada do modelo congelado\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=0.001, nesterov=True)\n",
        "\n",
        "full_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "full_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=63,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 30s 475ms/step - loss: 0.4998 - accuracy: 0.7925 - val_loss: 0.5336 - val_accuracy: 0.8133\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 29s 462ms/step - loss: 0.4403 - accuracy: 0.8070 - val_loss: 0.4595 - val_accuracy: 0.7933\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 29s 459ms/step - loss: 0.4179 - accuracy: 0.8195 - val_loss: 0.5321 - val_accuracy: 0.8133\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 29s 458ms/step - loss: 0.4097 - accuracy: 0.8200 - val_loss: 0.4860 - val_accuracy: 0.8133\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 28s 451ms/step - loss: 0.3848 - accuracy: 0.8335 - val_loss: 0.4813 - val_accuracy: 0.7467\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 28s 448ms/step - loss: 0.3947 - accuracy: 0.8270 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 28s 448ms/step - loss: 0.3801 - accuracy: 0.8385 - val_loss: 0.5251 - val_accuracy: 0.8133\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 28s 448ms/step - loss: 0.3788 - accuracy: 0.8325 - val_loss: 0.4568 - val_accuracy: 0.8267\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.3670 - accuracy: 0.8460 - val_loss: 0.4798 - val_accuracy: 0.8267\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 29s 461ms/step - loss: 0.3669 - accuracy: 0.8420 - val_loss: 0.5448 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55d5dc3cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctdjmXo7cWS_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "91379dd8-44d3-4d4b-d397-dadc2c11c319"
      },
      "source": [
        "evaluation_model(full_model, validation_generator)\n",
        "score = full_model.evaluate(validation_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc : 0.7555555555555555\n",
            "5/5 [==============================] - 1s 117ms/step - loss: 0.5448 - accuracy: 0.8200\n",
            "Valid loss: 0.5448468923568726\n",
            "Valid acc: 0.8199999928474426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8juBkVKEvQ7L"
      },
      "source": [
        "# Fine-Tuning\n",
        "5. Descongele as camadas da rede extratora de features e realize o fine-tuning da rede, continuando o\n",
        "treinamento (1,5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ-PlFZou2AB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d46e0779-0f78-4a0d-9047-afa77ad76463"
      },
      "source": [
        "model2 = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in model2.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "fine_model = tf.keras.Sequential([\n",
        "  model2,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Treinamento do modelo descongelado (fine-tuning)\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=0.001, nesterov=True)\n",
        "\n",
        "fine_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "fine_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=63,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 32s 508ms/step - loss: 0.4939 - accuracy: 0.7850 - val_loss: 0.5791 - val_accuracy: 0.7867\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 32s 503ms/step - loss: 0.3819 - accuracy: 0.8370 - val_loss: 0.4592 - val_accuracy: 0.8600\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 32s 501ms/step - loss: 0.3490 - accuracy: 0.8470 - val_loss: 0.5786 - val_accuracy: 0.8067\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 32s 504ms/step - loss: 0.3250 - accuracy: 0.8550 - val_loss: 0.6476 - val_accuracy: 0.8267\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 32s 504ms/step - loss: 0.2895 - accuracy: 0.8745 - val_loss: 0.7257 - val_accuracy: 0.8200\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 32s 503ms/step - loss: 0.2863 - accuracy: 0.8780 - val_loss: 0.5742 - val_accuracy: 0.8200\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 32s 501ms/step - loss: 0.2637 - accuracy: 0.8805 - val_loss: 0.7045 - val_accuracy: 0.8133\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 31s 495ms/step - loss: 0.2341 - accuracy: 0.8980 - val_loss: 0.7557 - val_accuracy: 0.8133\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 32s 504ms/step - loss: 0.2259 - accuracy: 0.9115 - val_loss: 0.7409 - val_accuracy: 0.8200\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 31s 496ms/step - loss: 0.2126 - accuracy: 0.9090 - val_loss: 0.6388 - val_accuracy: 0.8267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55d280a160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG8--Rnz3qPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a06cc67b-4628-4b78-8873-f31f9de7cf9c"
      },
      "source": [
        "evaluation_model(fine_model, validation_generator)\n",
        "score = fine_model.evaluate(validation_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc : 0.8147222222222222\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 0.6388 - accuracy: 0.8267\n",
            "Valid loss: 0.6388445496559143\n",
            "Valid acc: 0.8266666531562805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUV_nFR-viBH"
      },
      "source": [
        "# Avaliação do melhor modelo\n",
        "\n",
        "6. Avalie o melhor modelo no conjunto de teste (0,5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or4zG652vhwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "0514527f-3a28-4eb4-8c69-1494b4b9aed1"
      },
      "source": [
        "print(\"Modelo Baseline:\")\n",
        "evaluation_model(baseline_model, test_generator)\n",
        "score = baseline_model.evaluate(test_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])\n",
        "print()\n",
        "\n",
        "print(\"Modelo ResNet50 com camadas congeladas\")\n",
        "evaluation_model(full_model, test_generator)\n",
        "score = full_model.evaluate(test_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])\n",
        "print()\n",
        "\n",
        "print(\"Modelo ResNet50 com Fine-Tuning\")\n",
        "evaluation_model(fine_model, test_generator)\n",
        "score = fine_model.evaluate(test_generator)\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo Baseline:\n",
            "auc : 0.5956008564704217\n",
            "19/19 [==============================] - 3s 142ms/step - loss: 0.5054 - accuracy: 0.7967\n",
            "Valid loss: 0.5054080486297607\n",
            "Valid acc: 0.79666668176651\n",
            "\n",
            "Modelo ResNet50 com camadas congeladas\n",
            "auc : 0.7953318822884041\n",
            "19/19 [==============================] - 3s 154ms/step - loss: 0.4723 - accuracy: 0.8183\n",
            "Valid loss: 0.4722747206687927\n",
            "Valid acc: 0.8183333277702332\n",
            "\n",
            "Modelo ResNet50 com Fine-Tuning\n",
            "auc : 0.7753180796659058\n",
            "19/19 [==============================] - 3s 153ms/step - loss: 0.6074 - accuracy: 0.8250\n",
            "Valid loss: 0.6074337959289551\n",
            "Valid acc: 0.824999988079071\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnCzDZ7vq_B"
      },
      "source": [
        "# Conclusão\n",
        "7. Compare e interprete os resultados e elabore uma conclusão discutindo os experimentos (4,0).\n",
        "\n",
        "Nossas análises se encontram no relatório."
      ]
    }
  ]
}